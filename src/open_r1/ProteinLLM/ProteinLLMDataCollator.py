from typing import List, Dict, Any, Optional
import torch
from transformers import DataCollatorForLanguageModeling
from datasets import Dataset

class ProteinLLMDataCollator:
    """
    è›‹ç™½è´¨å¤šæ¨¡æ€æ•°æ®æ”¶é›†å™¨
    
    èŒè´£ï¼š
    1. æ¥æ”¶TRLæ ‡å‡†æ ¼å¼æ•°æ®ï¼ˆåŒ…å«textå’Œprotein_sequenceï¼‰
    2. ä½¿ç”¨ProteinLLMProcessorå¤„ç†åŒæ¨¡æ€æ•°æ®
    3. è¿”å›æ¨¡å‹æœŸæœ›çš„å®Œæ•´batchæ ¼å¼
    
    å·¥ä½œæµç¨‹ï¼š
    TRLæ•°æ® -> æå–è›‹ç™½è´¨åºåˆ— -> Processorå¤„ç† -> æ¨¡å‹è¾“å…¥æ ¼å¼
    """
    
    def __init__(self, processor, tokenizer, max_length_text: int = 512, max_length_protein: int = 100):
        self.processor = processor
        self.tokenizer = tokenizer
        self.max_length_text = max_length_text
        self.max_length_protein = max_length_protein
    
    def __call__(self, features: List[Dict[str, Any]]) -> Dict[str, torch.Tensor]:
        """
        å¤„ç†batchæ•°æ®
        
        Args:
            features: TRLä¼ å…¥çš„ç‰¹å¾åˆ—è¡¨ï¼Œæ¯ä¸ªfeatureåŒ…å«ï¼š
                - text: æ ¼å¼åŒ–åçš„å¯¹è¯æ–‡æœ¬ï¼ˆTRLå·²å¤„ç†ï¼‰
                - protein_sequence: è›‹ç™½è´¨åºåˆ—å­—ç¬¦ä¸²ï¼ˆåŸå§‹æ•°æ®ä¿ç•™ï¼‰
                
        Returns:
            batch: æ¨¡å‹æœŸæœ›çš„è¾“å…¥æ ¼å¼
                - input_ids: æ–‡æœ¬token IDs
                - attention_mask: æ–‡æœ¬attention mask
                - labels: è®­ç»ƒæ ‡ç­¾
                - protein_tokenized: è›‹ç™½è´¨tokenizationç»“æœ
                - batch_idx_map: è›‹ç™½è´¨åˆ°batchçš„æ˜ å°„
        """
        
        # ğŸ”§ æ­¥éª¤1ï¼šæå–æ•°æ®
        texts = []
        protein_sequences = []
        
        for feature in features:
            # æå–TRLæ ¼å¼åŒ–çš„æ–‡æœ¬
            if "text" in feature:
                texts.append(feature["text"])
            else:
                raise ValueError("DataCollator expects 'text' field from TRL processing")
            
            # æå–è›‹ç™½è´¨åºåˆ—
            if "protein_sequence" in feature:
                # ç¡®ä¿æ˜¯å­—ç¬¦ä¸²æ ¼å¼
                protein_seq = feature["protein_sequence"]
                if isinstance(protein_seq, list) and len(protein_seq) == 1:
                    protein_seq = protein_seq[0]
                elif isinstance(protein_seq, list):
                    raise ValueError(f"Expected 1 protein sequence per sample, got {len(protein_seq)}")
                protein_sequences.append(protein_seq)
            else:
                # æ²¡æœ‰è›‹ç™½è´¨åºåˆ—ï¼Œä½¿ç”¨å ä½ç¬¦
                protein_sequences.append("")
        
        # ğŸ”§ æ­¥éª¤2ï¼šä½¿ç”¨ä½ çš„Processorå¤„ç†åŒæ¨¡æ€æ•°æ®
        try:
            # è½¬æ¢ä¸ºProcessoræœŸæœ›çš„æ ¼å¼
            batch_protein_sequences = [[seq] for seq in protein_sequences if seq]
            
            if batch_protein_sequences:
                # æœ‰è›‹ç™½è´¨åºåˆ—çš„æƒ…å†µ
                batch = self.processor(
                    batch_protein_sequences=batch_protein_sequences,
                    text=texts,
                    max_length_text=self.max_length_text,
                    max_length_protein=self.max_length_protein,
                    return_tensors="pt",
                    padding=True,
                    truncation=True
                )
            else:
                # çº¯æ–‡æœ¬æƒ…å†µï¼ˆå¤‡é€‰æ–¹æ¡ˆï¼‰
                batch = self.processor.tokenizer(
                    texts,
                    max_length=self.max_length_text,
                    return_tensors="pt",
                    padding=True,
                    truncation=True
                )
                # æ·»åŠ ç©ºçš„è›‹ç™½è´¨ä¿¡æ¯
                batch["protein_tokenized"] = None
                batch["batch_idx_map"] = []
                
        except Exception as e:
            print(f"Processor error: {e}")
            # é™çº§å¤„ç†ï¼šçº¯æ–‡æœ¬
            batch = self.processor.tokenizer(
                texts,
                max_length=self.max_length_text,
                return_tensors="pt",
                padding=True,
                truncation=True
            )
            batch["protein_tokenized"] = None
            batch["batch_idx_map"] = []
        
        # ğŸ”§ æ­¥éª¤3ï¼šæ·»åŠ è®­ç»ƒæ ‡ç­¾
        batch["labels"] = batch["input_ids"].clone()
        
        # ğŸ”§ æ­¥éª¤4ï¼šç¡®ä¿batchå­—å…¸æ ¼å¼æ­£ç¡®
        if not isinstance(batch, dict):
            batch = dict(batch)
        
        return batch

class ProteinLLMDataCollatorForInference(ProteinLLMDataCollator):
    """æ¨ç†ä¸“ç”¨æ•°æ®æ”¶é›†å™¨ï¼ˆä¸ç”Ÿæˆlabelsï¼‰"""
    
    def __call__(self, features: List[Dict[str, Any]]) -> Dict[str, torch.Tensor]:
        batch = super().__call__(features)
        # ç§»é™¤labelsï¼Œä¿ç•™å…¶ä»–å­—æ®µç”¨äºæ¨ç†
        if "labels" in batch:
            del batch["labels"]
        return batch