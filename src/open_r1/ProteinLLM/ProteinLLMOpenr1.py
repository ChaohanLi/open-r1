"""
Open-R1æ¡†æ¶é›†æˆæ¨¡å—
æä¾›æ ‡å‡†æ¥å£ï¼Œä¾¿äºé›†æˆåˆ°Open-R1çš„SFTå’ŒGRPOæµç¨‹ä¸­
"""

from typing import Optional, Dict, Any
from transformers import PreTrainedModel, PreTrainedTokenizer
from datasets import Dataset

from .ProteinLLMModel import ProteinLLMModel, ProteinLLMConfig
from .ProteinDataCollator import ProteinLLMDataCollator, ProteinLLMDataCollatorForInference

def get_protein_llm_model(
    text_model_name: str = "Qwen/Qwen2.5-Math-7B",
    protein_model_name: str = "facebook/esm2_t33_650M_UR50D",
    **kwargs
) -> ProteinLLMModel:
    """
    å·¥å‚å‡½æ•°ï¼šåˆ›å»ºè›‹ç™½è´¨LLMæ¨¡å‹
    å…¼å®¹Open-R1çš„get_modelæ¥å£
    """
    config = ProteinLLMConfig(
        text_model_name=text_model_name,
        protein_model_name=protein_model_name,
        **kwargs
    )
    return ProteinLLMModel(config=config)

def get_protein_data_collator(
    model: ProteinLLMModel,
    max_length_text: int = 512,
    max_length_protein: int = 100,
    for_inference: bool = False
) -> ProteinLLMDataCollator:
    """
    å·¥å‚å‡½æ•°ï¼šåˆ›å»ºè›‹ç™½è´¨æ•°æ®æ”¶é›†å™¨
    å…¼å®¹Open-R1çš„æ•°æ®å¤„ç†æµç¨‹
    """
    if for_inference:
        return ProteinLLMDataCollatorForInference(
            processor=model.processor,
            tokenizer=model.text_tokenizer,
            max_length_text=max_length_text,
            max_length_protein=max_length_protein
        )
    else:
        return ProteinLLMDataCollator(
            processor=model.processor,
            tokenizer=model.text_tokenizer,
            max_length_text=max_length_text,
            max_length_protein=max_length_protein
        )

def prepare_protein_dataset(dataset: Dataset) -> Dataset:
    """
    å‡†å¤‡è›‹ç™½è´¨æ•°æ®é›†ï¼Œç¡®ä¿æ ¼å¼å…¼å®¹
    """
    def check_format(example):
        # éªŒè¯æ•°æ®æ ¼å¼
        if "messages" not in example:
            raise ValueError("Dataset must contain 'messages' field")
        if "protein_sequence" not in example:
            raise ValueError("Dataset must contain 'protein_sequence' field")
        return example
    
    return dataset.map(check_format)

# ğŸ”§ ä¸ºOpen-R1æä¾›çš„æ ‡å‡†æ¥å£
class ProteinLLMForOpenR1:
    """
    Open-R1æ¡†æ¶é€‚é…å™¨
    æä¾›æ ‡å‡†æ¥å£ä¾›SFTå’ŒGRPOä½¿ç”¨
    """
    
    def __init__(self, model_config: Dict[str, Any]):
        self.model = get_protein_llm_model(**model_config)
        self.data_collator = get_protein_data_collator(self.model)
    
    def get_model(self) -> PreTrainedModel:
        return self.model
    
    def get_tokenizer(self) -> PreTrainedTokenizer:
        return self.model.text_tokenizer
    
    def get_data_collator(self, for_inference: bool = False):
        return get_protein_data_collator(self.model, for_inference=for_inference)
    
    def prepare_dataset(self, dataset: Dataset) -> Dataset:
        return prepare_protein_dataset(dataset)